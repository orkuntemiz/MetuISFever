{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A folder path, a file path, or a list of file paths is needed\n",
    "\n",
    "# DATA_LOCATION = \"wiki_pages\"\n",
    "# DATA_LOCATION = \"wiki_pages/wiki_000.jsonl\"\n",
    "DATA_LOCATION = [\n",
    "    \"wiki_pages/wiki_000.jsonl\",\n",
    "    \"wiki_pages/wiki_001.jsonl\",\n",
    "    \"wiki_pages/wiki_002.jsonl\",\n",
    "    \"wiki_pages/wiki_003.jsonl\",\n",
    "    \"wiki_pages/wiki_004.jsonl\",\n",
    "]\n",
    "OUTPUT_FOLDER = \"wiki_pages_anserini\"\n",
    "\n",
    "SIMPLIFY_PAGE_LINKS = False\n",
    "PREFER_URL_FOR_LINKS = False\n",
    "\n",
    "# If SIMPLIFY_PAGE_LINKS and not PREFER_URL_FOR_LINKS: [[Page_(disambiguation)|Page Title]] -> Page Title\n",
    "# If SIMPLIFY_PAGE_LINKS and PREFER_URL_FOR_LINKS: [[Page_(disambiguation)|Page Title]] -> Page (disambiguation)\n",
    "# Note that the URL basename can sometimes contain extra information, but it can also redirect to a page that is different than the visible label.\n",
    "\n",
    "SUBSECTION_SEP = \"|\"\n",
    "SUBSUBSECTION_SEP = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 file(s) will be processed.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "to_process = None\n",
    "\n",
    "if type(DATA_LOCATION) == list:  # A list of file paths\n",
    "    to_process = [file for file in DATA_LOCATION]\n",
    "elif os.path.isfile(DATA_LOCATION):  # A file path\n",
    "    to_process = [DATA_LOCATION]\n",
    "elif os.path.isdir(DATA_LOCATION):  # A folder\n",
    "    to_process = glob.glob(\"{}/*.jsonl\".format(DATA_LOCATION))\n",
    "else:\n",
    "    raise ValueError(\"Data location is not a valid file or folder.\")\n",
    "\n",
    "print(\"{} file(s) will be processed.\".format(len(to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_value(value):\n",
    "    \"\"\"Replaces unnecessary space (including \\t and such) with a single space\n",
    "    character.\n",
    "\n",
    "    Arg:\n",
    "        value: A string.\n",
    "\n",
    "    Returns:\n",
    "        The simplified version of the provided string.\n",
    "    \"\"\"\n",
    "    return \" \".join(value.split())\n",
    "\n",
    "\n",
    "def final_clean(\n",
    "    field,\n",
    "    simplify_page_links=SIMPLIFY_PAGE_LINKS,\n",
    "    prefer_url_for_links=PREFER_URL_FOR_LINKS,\n",
    "):\n",
    "    \"\"\"Removes multiple space characters with a single space character. Removes\n",
    "    leading and trailing spaces. Simplifies the page links according to the\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        field (str): A field of the processed page data.\n",
    "        simplify_page_links (Boolean): A Boolean indicating whether the page\n",
    "            links must be simplified. By default, it is set to\n",
    "            SIMPLIFY_PAGE_LINKS.\n",
    "        prefer_url_for_links (Boolean): A Boolean indicating whether the page\n",
    "            links must be simplified to the URL basename instead of the link's\n",
    "            label. By default, it is set to SIMPLIFY_PAGE_LINKS.\n",
    "\n",
    "    Returns:\n",
    "        str: The simplified version of the provided string.\n",
    "    \"\"\"\n",
    "    field = re.sub(\" +\", \" \", field.strip(), flags=re.MULTILINE)\n",
    "    if SIMPLIFY_PAGE_LINKS and PREFER_URL_FOR_LINKS:\n",
    "        # Simplifies links by replacing them with the URL basename (replaces underscores)\n",
    "        # Underscores are replaced with space\n",
    "        field = re.sub(r\"(?:\\[\\[)(.*)?(?:\\|)\", field.replace(\"_\", \" \"), field)\n",
    "        field = re.sub(r\"(\\|).*?(\\]\\])|\\[\\[\", \"\", field, flags=re.MULTILINE)\n",
    "    elif SIMPLIFY_PAGE_LINKS:\n",
    "        # Simplifies links by replacing them with the titles\n",
    "        field = re.sub(r\"(\\[\\[).*?(\\|)|]]\", \"\", field, flags=re.MULTILINE)\n",
    "    return field\n",
    "\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):  # Creates the output folder if it does not exist\n",
    "    os.mkdir(OUTPUT_FOLDER)\n",
    "\n",
    "counter = 0\n",
    "for file_path in to_process:\n",
    "    file_basename = os.path.basename(file_path)\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, file_basename)\n",
    "\n",
    "    open(output_path, mode=\"w\").close()  # Creating an empty output file\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_data = [json.loads(line) for line in f]\n",
    "\n",
    "    for page in file_data:\n",
    "\n",
    "        page_data_processed = {\"id\": page[\"title\"], \"text\": \"\", \"lines\": \"\"}\n",
    "\n",
    "        # The order list of the page will be used to parse the items\n",
    "        for item_id, item in enumerate(page[\"order\"]):\n",
    "            if item.startswith(\"sentence_\"):  # Sentence\n",
    "                clean_element = clean_value(page[item])\n",
    "                page_data_processed[\"text\"] += \" {}\".format(clean_element)\n",
    "                page_data_processed[\"lines\"] += \"{}\\t{}\\n\".format(item, clean_element)\n",
    "            elif item.startswith(\"table_\"):  # Table\n",
    "                page_data_processed[\"text\"] += \" \"\n",
    "                page_data_processed[\"lines\"] += \"{}\\t\".format(item)\n",
    "                table_rows = []\n",
    "                for row in page[item][\"table\"]:\n",
    "                    row_items = []\n",
    "                    for cell in row:\n",
    "                        row_items.append(clean_value(cell[\"value\"]))\n",
    "\n",
    "                    row_text = \"{}\".format(SUBSUBSECTION_SEP).join(row_items)\n",
    "                    table_rows.append(row_text)\n",
    "\n",
    "                if \"caption\" in page[item]:\n",
    "                    table_rows.append(clean_value(page[item][\"caption\"]))\n",
    "\n",
    "                table_text = \"{}\".format(SUBSECTION_SEP).join(table_rows)\n",
    "                page_data_processed[\"text\"] += table_text\n",
    "                page_data_processed[\"lines\"] += table_text\n",
    "                page_data_processed[\"lines\"] += \"\\n\"\n",
    "            elif item.startswith(\"section_\"):  # Section\n",
    "                clean_element = clean_value(page[item][\"value\"])\n",
    "                page_data_processed[\"text\"] += \" {}\".format(clean_element)\n",
    "                page_data_processed[\"lines\"] += \"{}\\t{}\\n\".format(item, clean_element)\n",
    "            elif item.startswith(\"list_\"):  # List\n",
    "                list_items = []\n",
    "                for list_item in page[item][\"list\"]:\n",
    "                    list_items.append(clean_value(list_item[\"value\"]))\n",
    "\n",
    "                list_text = \"{}\".format(SUBSECTION_SEP).join(list_items)\n",
    "                page_data_processed[\"text\"] += list_text\n",
    "                page_data_processed[\"lines\"] += \"{}\\t{}\\n\".format(item, list_text)\n",
    "            else:  # All alternatives must be handled and the code must not reach here\n",
    "                raise ValueError(\"Unidentified page element found.\")\n",
    "\n",
    "        page_data_processed[\"text\"] = final_clean(page_data_processed[\"text\"])\n",
    "        page_data_processed[\"lines\"] = final_clean(page_data_processed[\"lines\"])\n",
    "\n",
    "        # Appending the processed page data to the file\n",
    "        with open(output_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            json.dump(page_data_processed, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
